What would you think if technology was made that could tell every emotion someone has, at any time of day? Well, pretty soon you may know first-hand, as our current technology is actually well underway to reaching that level. As of right now, a new software has been developed that can percieve emotions in others faces, using several different variables. It is known as the Facial Action Coding System, and judge six different emotions. The question is, how does such a machine work, and how can we know if this machine holds any value in a classroom setting?

Before taking a further look at whether such an ability is needed in classrooms, it is imperative to first understand just how the Facial Action Coding System works. It starts by analyzing the face and constructing a 3-D model of it, so that the 44 major muscles in the face can be easily captured. Then, the system labels slight muscle movements -known as action units- in the face and uses those to calculate emotions. As of right now, there are six classified emotions to compare the facial muscle movements to: Happiness, surprise, anger, disgust, fear, and sadness.

The question is, how does this machine gather muscle movements as a certain type of emotion? How that works is the human body has similar facial expressions for certain moods, such as raising eyebrows when surprised. These are automatic in just about everybody, making it way easier to gather emotions. If someone were to, for example, tighten their lips, near everyone could understand the possible tension and anger from the person. Thanks to the easy understanding of facial patterns, the machine can too!

The science of facial mucle patterns may not be completely understoood, but there currently are ideas that maybe making certain faces can change your mood! According to the Facial Feedback Theory of Emotion, moving your facial muscles not only displays emotions, but it may help produce them as well! This is due to the empathy that may occur when imitating someone's facial patterns, even if one is unaware they are. With this information, we can understand the complexity of human emotion a little better, and possibly gather a conclusion from all of this that goes for this technology in schools. The question is, just what have we gathered and understood so far?

In conclusion, there were several take-aways from this article. For starters, the machine can evaluate six emotions, which are happiness, surprise, anger, disgust, fear, and sadness. It does this via the understanding of the human facial muscles and the different ways we physically convey emotion. And not only that, but when someone may be only appearing as an emotion/set of emotions, they can subconsciously mold into that emotion. From all of this, only one sound conclusion can be made. The use of this technology is valuable in classrooms, as well as outside of school, due to the fact that it helps to recognize facial emotions in students and teachers alike so that they are more aware of their surroundings.