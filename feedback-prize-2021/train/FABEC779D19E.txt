She's 83 percent happy, 9 percent disgusted, 6 percent fearful, and 2 percent angry. Wait, anger and disgust is rising? Happiness is plummeting? What is happening? The answer is that this emotion reading technology, though interesting, could actually have a very negative effect on the people it is used on. Especially in a class room, one of the most influential places on a childs life. Sure, it is cool being able to read Mona Lisa's emotions, but on real students a facial action coding system would be impractical, invasive, and damaging.

Being able to detect other peoples emotions is a scary idea, but even before diving into the effects it could have on the mind, it's physical restraints are just as daunting. In paragraph seven, the article states "Your home PC can't handle the complex algorithms used to decode Mona Lisa's smile." Schools are already struggling to keep up with the cost of electronics for thousands of students, and having to get new laptops or computers to implemenet this technology would be extremely expensive and unwise. Especially when many schools have real problems that need to be addressed such as a larger special needs program, or more funding to the band who hasn't gotten new uniforms in twenty years. Then once all this money is invested, what if it does not work. This technology is clearly just starting to develop, and it runs solely on facial muscles. The article tells you how to raise your cheek muscles to show a real smile, surely students would find ways to exploit this and fake emotions, rendering the technology ineffective. Most importantly, schools are a fast paced environment, adding this technology and teaching the students how to use it would waste a lot of time that could have been devoted to learning. The other option would be to implement it and not tell them at all, but that would be a clear invasion of privacy and could get the school in legal and financial trouble.

All of this is assuming the school would even want the technology. It sounds very nifty at a glance, but the idea itself is actually extrememly invasive. Emotions are the secret to what's going on in our brain, all of our deepest thoughts and desires are secretly expressed in our emotions, sometimes very subtley. Kids are very secretive, and would almost certainly not take kindly to having there personal emotions, and by extension, what they are thinking about, out in the open. The author says that this technology in a class room would help recognize when a student becomes "confused or bored," but what about all the other emotions that would come with it: the sadness over a lost loved one, the love a teen is feeling towards their crush. These emotions are deeply personal, and if a child wanted to share them he would tell you. Stealing them away with technology is a clear invasion of privacy.

This type of invasion isn't just unkind, it could, instead of helping, actually damage a students emotional or mental well being. Emotions can be a rollercoaster. Everyone has their own way of handling them , and for some people getting them intensly analyzed is not the answer. In fact, this type of prying could cause students to retract into themself, and lower self confidence. For example, if a teen is always being reminded he is feeling sad, won't that just further his sadness? Then, if students don't want to share their emotions, they may start using their facial muscles to trick the machine into thinking they are feeling a certain way. One of the number one things all psychologists will tell their patients in dealing with emotions is not to cover them up and hide them behind other emotions. Constantly being in a state of hiding with emotions could cause students to snap in a bad way.

The last thing students of any age need is more problems to worry about. Emotions are a large, personal part of anyone's life, and to try and analyze them in a classroom setting would be impractical, invasive, and damaging.