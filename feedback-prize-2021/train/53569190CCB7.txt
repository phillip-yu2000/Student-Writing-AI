Imagine, being like Will Smith in the movie 'iRobot,' and being able to relax while your car drives for you. But then, realize, that his car ends up almost killing him. Some people may agree with self-driving cars, and some may not agree with them. Well, in my opinion, I believe that cars that can drives themselves are bad. Here is why. The cars technology can fail, they can lose signal, and they don't know who is responsible for wrecks.

In the article, it explains how these cars have a lot of high tech equipment. Well, what happens when this fails? For example, what happens when the vehicals 3-D sensor goes out and the human driver relies on this way to much? They could get in a wreck, and seriously hurt themselves, or someone else.

Secondly, in the article, it said that cars have a GPS gadet that helps them drive. Well, what happens when the GPS that helps drive the car loses it's signal? The car could get lost, start swerving, or even go off the road. With this happening, the company could get sued. The human driver could even fork out a lot of money to repair the system, or the whole car.

Finally, the article stats that if the car wrecks itself, they wouoldn't know who would be responsible. It makes sense though. If the car wrecked, it doesn't always mean it's the cars fault. The driver could be asleep, or doing something distracting. But who would know this, the car, or a human? With these cars getting involved in wrecks, who is to blame? A human who can pleade his case, or a car that can drive itself?

All in all, I don't believe that cars should be able to drive themselves. Yes, it would be nice to be like Will Smith in 'iRobot,' and not have to drive, but I believe it is to dangerous. I don't support self driving cars, because their technology can fail, they can lose their GPS driving signal, and they can't even figure out who to blame for a wreck. So, where do you stand, or should I say drive, with this new technology delemia?