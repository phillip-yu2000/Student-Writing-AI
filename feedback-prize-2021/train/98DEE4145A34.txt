Driverless cars are not good because they could be dangerous because machines and equipment are known to malfunction. It is a proven fact that factory equipment, power tools, and even common cellphones malfunction, so it could pose a huge danger if a car were to malfunction.

When a human is driving a car and makes a mistake, yes it is bad that they made a mistake, but at least you can hold somebody responsible for it and have them move on from their mistake. If there is no driver and the car malfunctions on its own, yes you can improve the car, but can you hold the car responsible? One can certainly move on and gain knowledge from making mistakes, its how mankind evolves, but just how far can you force a car to evolve is the question... What if one day a car on a highway moving 70 mph malfunctioned and started spinning out of control. No would would be able to stop it because it is so "evolved" that the car is expected to just "do it on its own", but what if it falters in a moment of weakness and can't?

Also, humans are ever growing in knowledge and expanding their horizons of learning, but just how far can a car actually go? Just how much can you teach a car before you can't teach it anymore? This could become an issue when it comes to road safety improvement because yes, technology is always evolving and improving, but how far are we willing to go in letting technology take over our whole lives? How far is the car willing to go before it decides it can't take anymore?

It is because of these reasons that driverless cars pose a threat to people because they are unreliable, not always evolving, and in certain times untrustworthy. 