The idea of using facial recognition technology to identify how someone is feeling is a new one. It is also a preposturous one. You cannot fully understand what someone is feeling by looking at their face, and attempting to do so is an invasion of their privacy. Facial action coding systems should not be used in classrooms.

The idea that you could fully decipher what someone is feeling based on how they look is absurd. You cannot decide for yourself how someone feels based on the movement of their muscles. For example, if someone looks sad, you cannot just decide that they are sad, just because they look that way. If a machine decides I look confused, does it really have the right to change what I am learning? To understand how someone is really feeling, you have to first ask yourself why they might be feeling that way. Once you understand this, then you can determine what is happening. A machine cannot read minds. If I am confused about one thing, the machine does not know what. Not to mention that people often feel varying emotions at varying times of the day. I might be sad one minute, then laugh at a joke the next. I might not understand something, than understand it in the next second. The machine might automatically change something I understood based on a few seconds of confusion. This is not efficient or helpful.

To read someone's emotions based on their facial expressions is an invasion of their privacy. Let's assume this machine can accurately decipher someone's emotions based on muscle movement. What if you don't want people to know how you're feeling? If I am confused about something, and I am embarrased about it, suddenly the whole word knows. It should be up to the student to decide whether or not they want to seek help, not some magical machine. By forcing students to share private emotions, you run the risk of making them less willing to go to school. Who would want to go to a school where everyone knows how you feel at all times of the day? That would affect learning severely, and would definitely do more harm than good. Hindering learning in an attempt to better understand students is not worth it.

Using this software in classrooms would be ineffective, and even if it did work, it would be a huge invasion of privacy. This software should be used on paintings and nothing more. It is not accurate enough to do anything other than hold back human learning. This software is not fit for classrooms. 